{
 "metadata": {
  "name": "",
  "signature": "sha256:ba459add0ac156340d2c681643d8f34ec2d55bb1664c6b45fb54d0aa4ba68aca"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Pembuatan Profil Navigasi Pengguna Website\n",
      "\n",
      "<h3>Import Python Module yang diperlukan</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import sys, pycountry,re,gensim,enchant,random\n",
      "import numpy as np\n",
      "from pymongo import MongoClient\n",
      "from langdetect import detect\n",
      "from pytz import country_names\n",
      "from gensim import corpora, models, similarities\n",
      "from bson.son import SON\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "enchant.set_param(\"enchant.myspell.dictionary.path\",r\"C:\\Python278\\Lib\\site-packages\\enchant\\share\\enchant\\myspell\")\n",
      "d = enchant.Dict(\"id_ID\")\n",
      "d_en = enchant.Dict(\"en_US\")\n",
      "\n",
      "client = MongoClient('localhost', 27017)\n",
      "db = client.gudegnet\n",
      "article_used = db.article_directory"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Scraping Content dari Gudegnet</h3>"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "scrapy crawl gudegnet"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Cek Data yang sudah ter scraping (dalam kasus ini gudegnet)</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "client = MongoClient('localhost', 27017)\n",
      "db = client.gudegnet\n",
      "articles = db.articles_raw\n",
      "count_article = articles.count()\n",
      "print \"Artikel yang sudah di Scrap = \" + str(count_article)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Artikel yang sudah di Scrap = 9310\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Format data yang telah di scrap, biasanya masih terpisah-pisah, harus di join</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "client = MongoClient('localhost', 27017)\n",
      "db = client.gudegnet\n",
      "\n",
      "posts = db.articles_raw\n",
      "article_concat = db.article_clean\n",
      "i = 0\n",
      "article_str = \"\"\n",
      "article_concat.remove({})\n",
      "empty_article = 0\n",
      "for post in list(posts.find()):\n",
      "    i = i+1\n",
      "    article_str = \" \".join(post['article_html'])\n",
      "    article_str = article_str.strip()\n",
      "    lang = \"not_detected\"\n",
      "    try:\n",
      "        lang = detect(article_str)\n",
      "    except UnicodeDecodeError:\n",
      "        lang = detect(article_str.decode(\"UTF-8\"))\n",
      "    except:\n",
      "        if(article_str == \"\"):\n",
      "            empty_article = empty_article+1\n",
      "        else:\n",
      "            print \"Not Detected = \" + article_str\n",
      "    article_concat.insert({\"url\":post['url'],'article':article_str,'lang':lang,'topic':'-'});\n",
      "\n",
      "\n",
      "print 'Clean in ',str(i),' Success!'\n",
      "print \"Not Detected,\"+ str(empty_article) +\" Empty Article!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Lihat Status Artikel yang sudah di Clean, beserta bahasanya</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "article_clean = article_used\n",
      "str_lang = \"\"\n",
      "sizes = []\n",
      "labels = []\n",
      "count_article = article_clean.count()\n",
      "for found_lang in article_clean.distinct('lang'):\n",
      "    if found_lang=='id' or found_lang=='en':\n",
      "        count_lang = article_clean.find({'lang':found_lang}).count()\n",
      "        sizes.append((count_lang))\n",
      "        if found_lang!='not_detected':\n",
      "            ctry = pycountry.languages.get(alpha2=found_lang)\n",
      "            labels.append(ctry.name)\n",
      "            str_lang = str_lang + str(ctry.name) + ' : ' + str(count_lang)+'\\n'\n",
      "        else:\n",
      "            str_lang = str_lang + \"Not Detected \" + ' : ' + str(count_lang)+'\\n'\n",
      "            labels.append(\"Not Detected\")\n",
      "\n",
      "print 'Cleaned Article : ',str(count_article),'\\nFound = \\n',str_lang,''\n",
      "\n",
      "colors = ['yellowgreen', 'lightskyblue']\n",
      "explode = (0, 0.1) # only \"explode\" the 2nd slice (i.e. 'Hogs')\n",
      "\n",
      "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
      "        autopct='%1.1f%%', shadow=True, startangle=90)\n",
      "# Set aspect ratio to be equal so that pie is drawn as a circle.\n",
      "plt.axis('equal')\n",
      "\n",
      "plt.show()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pemodelan Topik dengan LDA Bahasa Indonesia"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "def is_number(s):\n",
      "    try:\n",
      "        float(s)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "\n",
      "stop = open('lda/stoplist-bahasa')\n",
      "stopstr = stop.readline()\n",
      "\n",
      "articles = article_used\n",
      "docset = []\n",
      "\n",
      "for article in list(articles.find({'lang':'id'})):\n",
      "    artic = re.sub(r'([^\\s\\w]|_)+', '', article['article'])\n",
      "    docset.append(artic)\n",
      "print \"Pembuatan Docset Sukses..\"\n",
      "stoplist = set(stopstr.split())\n",
      "texts = [[word for word in document.lower().split() if (word not in stoplist and len(word)>1 and is_number(word)==False and d.check(word)==True)] for document in docset]\n",
      "#all_tokens = sum(texts, [])\n",
      "all_tokens = ''.join(str(v) for v in texts)\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once] for text in texts]\n",
      "print \"Penghilangan Stopword Sukses..\"\n",
      "dictionary = corpora.Dictionary(texts)\n",
      "dictionary.save('lda/gudegarticle.dict')\n",
      "dictionary.save_as_text('lda/gudegarticle_dict.txt')\n",
      "print \"Pembuatan Dictionary Sukses..\"\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "corpora.MmCorpus.serialize('lda/gudegarticlecorpus.mm', corpus) # store to disk, for later use\n",
      "print \"Pembuatan Corpus Sukses..\"\n",
      "id2word = gensim.corpora.Dictionary.load_from_text('lda/gudegarticle_dict.txt')\n",
      "mm = gensim.corpora.MmCorpus('lda/gudegarticlecorpus.mm')\n",
      "number_of_topic = 14\n",
      "lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=number_of_topic, update_every=5, eval_every=1,chunksize=10, passes=1)\n",
      "\n",
      "lda.save('lda/model_gudeg')\n",
      "\n",
      "print \"Pembuatan Model LDA Sukses!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Pemodelan Topik LDA Bahasa Inggris"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_number(s):\n",
      "    try:\n",
      "        float(s)\n",
      "        return True\n",
      "    except ValueError:\n",
      "        return False\n",
      "\n",
      "stop = open('lda/stoplist-english')\n",
      "stopstr = stop.readline()\n",
      "\n",
      "articles = article_used\n",
      "docset = []\n",
      "\n",
      "for article in list(articles.find({'lang':'en'})):\n",
      "    artic = re.sub(r'([^\\s\\w]|_)+', '', article['article'])\n",
      "    docset.append(artic)\n",
      "print \"Pembuatan Docset Sukses..\"\n",
      "stoplist = set(stopstr.split())\n",
      "texts = [[word for word in document.lower().split() if (word not in stoplist and len(word)>1 and is_number(word)==False and d_en.check(word)==True)] for document in docset]\n",
      "#all_tokens = sum(texts, [])\n",
      "all_tokens = ''.join(str(v) for v in texts)\n",
      "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
      "texts = [[word for word in text if word not in tokens_once] for text in texts]\n",
      "print \"Penghilangan Stopword Sukses..\"\n",
      "dictionary = corpora.Dictionary(texts)\n",
      "dictionary.save('lda/gudegarticle_en.dict')\n",
      "dictionary.save_as_text('lda/gudegarticle_dict_en.txt')\n",
      "print \"Pembuatan Dictionary Sukses..\"\n",
      "corpus = [dictionary.doc2bow(text) for text in texts]\n",
      "corpora.MmCorpus.serialize('lda/gudegarticlecorpus_en.mm', corpus) # store to disk, for later use\n",
      "print \"Pembuatan Corpus Sukses..\"\n",
      "id2word = gensim.corpora.Dictionary.load_from_text('lda/gudegarticle_dict_en.txt')\n",
      "mm = gensim.corpora.MmCorpus('lda/gudegarticlecorpus_en.mm')\n",
      "number_of_topic = 14\n",
      "lda = gensim.models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=number_of_topic, update_every=5, eval_every=1,chunksize=10, passes=1)\n",
      "\n",
      "lda.save('lda/model_gudeg_en')\n",
      "\n",
      "print \"Pembuatan Model LDA Bahasa Inggris Sukses!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Tampilkan Topik"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "print \"TOPIK BAHASA INDONESIA = \\n\"\n",
      "lda = gensim.models.LdaModel.load('lda/model_gudeg')\n",
      "model_str = \"\"\n",
      "for i in range(number_of_topic):\n",
      "    model_str = model_str + \"Topik \" + str(i) + \" = \" + str(lda.print_topic(i)) + '\\n==========\\n'\n",
      "print model_str\n",
      "\n",
      "\n",
      "print \"TOPIK BAHASA INGGRIS = \\n\"\n",
      "lda_en = gensim.models.LdaModel.load('lda/model_gudeg_en')\n",
      "model_str = \"\"\n",
      "for i in range(number_of_topic):\n",
      "    model_str = model_str + \"Topik \" + str(i) + \" = \" + str(lda_en.print_topic(i)) + '\\n==========\\n'\n",
      "print model_str"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TOPIK BAHASA INDONESIA = \n",
        "\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'number_of_topic' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-979e6e6d5e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lda/model_gudeg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber_of_topic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mmodel_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_str\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"Topik \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n==========\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mmodel_str\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'number_of_topic' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3>Assign Topik ke Artikel</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "lda = gensim.models.LdaModel.load('lda/model_gudeg')\n",
      "    \n",
      "dicts = corpora.Dictionary.load_from_text('lda/gudegarticle_dict.txt')\n",
      "\n",
      "articles = article_used\n",
      "for article in list(articles.find({'lang':'id'})):\n",
      "    artic = re.sub(r'([^\\s\\w]|_)+', '', article['article'])\n",
      "    result = lda[dicts.doc2bow(artic.lower().split())]\n",
      "    maxs = 0\n",
      "    topic_selected = 0\n",
      "    for res in result:\n",
      "        if res[1]>maxs:\n",
      "            maxs=res[1]\n",
      "            topic_selected = res[0]\n",
      "    #print \"Topik : \", topic_selected, \" dengan nilai \",max, \" ==> \",result\n",
      "    #article_indo.insert({\"url\":article['url'],'article':article['article'],'topik':topic_selected});\n",
      "    articles.update({\"_id\":article['_id']},{\"$set\":{'topic':topic_selected}})\n",
      "print \"Assign Topik ke Artikel Bahasa Indonesia Berhasil Dilakukan! \\n\"\n",
      "\n",
      "lda = gensim.models.LdaModel.load('lda/model_gudeg_en')\n",
      "    \n",
      "dicts = corpora.Dictionary.load_from_text('lda/gudegarticle_dict_en.txt')\n",
      "\n",
      "for article in list(articles.find({'lang':'en'})):\n",
      "    artic = re.sub(r'([^\\s\\w]|_)+', '', article['article'])\n",
      "    result = lda[dicts.doc2bow(artic.lower().split())]\n",
      "    maxs = 0\n",
      "    topic_selected = 0\n",
      "    for res in result:\n",
      "        if res[1]>maxs:\n",
      "            maxs=res[1]\n",
      "            topic_selected = res[0]\n",
      "    #print \"Topik : \", topic_selected, \" dengan nilai \",max, \" ==> \",result\n",
      "    #article_indo.insert({\"url\":article['url'],'article':article['article'],'topik':topic_selected});\n",
      "    articles.update({\"_id\":article['_id']},{\"$set\":{'topic':\"en\"+str(topic_selected)}})\n",
      "print \"Assign Topik ke Artikel Berhasil Dilakukan!\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lihat Random Artikel dengan Topik Tertentu"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "articles = article_used\n",
      "\n",
      "for article in list(articles.find({\"topic\":5}).limit(15)):\n",
      "    print article['article'],\"\\n========================\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lihat Banyaknya Artikel Per Topik"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "count_topic = articles.aggregate([{\"$group\":{\"_id\":\"$topic\",\"count\":{\"$sum\":1}}},{\"$sort\": SON([(\"count\", -1)])}])\n",
      "count_topic_list = []\n",
      "topic_list = []\n",
      "for result in count_topic['result']:\n",
      "    print \"Topik \", result['_id'],\" berjumlah \",result['count'],\" artikel\"\n",
      "    count_topic_list.append(result['count'])\n",
      "    topic_list.append(result['_id'])\n",
      "\n",
      "fig = plt.figure()   \n",
      "ax = fig.add_subplot(111)\n",
      "width = 0.8\n",
      "opacity = 0.4\n",
      "ind = np.arange(number_of_topic*2+1)\n",
      "\n",
      "rects1 = plt.bar(ind, count_topic_list, width,\n",
      "                color='r',\n",
      "                label='Topik')\n",
      "\n",
      "plt.xlabel('Topik')\n",
      "plt.ylabel('Artikel')\n",
      "plt.title('Jumlah Artikel dalam Topik')\n",
      "plt.xticks(ind+width/2., topic_list )\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}